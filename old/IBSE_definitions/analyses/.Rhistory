allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(serves|serving)", replacement="serve")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(sessions)", replacement="session")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(sets)", replacement="set")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(settings)", replacement="setting")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(shaped|shaping)", replacement="shape")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(shared)", replacement="share")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(shifts)", replacement="shift")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(shows)", replacement="shown")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(similarities|similarly)", replacement="similar")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(simply)", replacement="simple")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(simulated|simulations)", replacement="simulation")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(sinking)", replacement="sink")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(situated|situating)", replacement="situate")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(situations)", replacement="situation")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(skills)", replacement="skill")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(smaller)", replacement="small")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(solely)", replacement="sole")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(solutions)", replacement="solution")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(solving)", replacement="solve")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(sources)", replacement="source")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(specification|specified|specifying)", replacement="specify") #HMMM
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(stages)", replacement="stage")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(started|starting|starts)", replacement="start")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(statement|statements|states|stated)", replacement="state")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(step1|step2|step3|step4|steps|step)", replacement="phase") #HMMMMM CHECK THIS OUT!!
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(stimulated|stimulating|stimuli)", replacement="stimulate") #HMMMM
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(stories)", replacement="story")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(strongly)", replacement="strong")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(structural|structured|structures|structuring)", replacement="structure")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(studentcentered|studentdirected)", replacement="studentcentred")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(students)", replacement="student")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(studied|studies)", replacement="study")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(subjects)", replacement="subject")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(subsequently)", replacement="subsequent")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(successful|successfully)", replacement="success")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(suggested)", replacement="suggest")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(summarized|summarizes|summarizing|summary)", replacement="summarize")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(supported|supporting|supports)", replacement="support")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(surrounding|surrounds)", replacement="surround")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(systematically)", replacement="systematic")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(taken|takes|taking)", replacement="take")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(talked)", replacement="talk")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(targeted|targeting|targets)", replacement="target")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(tasks)", replacement="task")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(teacher's|teachers|teaching)", replacement="teacher")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(technological|technologies)", replacement="technology")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(terms)", replacement="term")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(testing)", replacement="test")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(theoretical|theories|theories.|theory)", replacement="theory")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(thoughts)", replacement="thought")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(topics)", replacement="topic")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(tracked|tracking)", replacement="track")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(transformations)", replacement="transformation")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(translated|translates)", replacement="translate")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(type|types)", replacement="type")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(typically)", replacement="typical")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(understanding|understandings|understood)", replacement="understand")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(units)", replacement="unit")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(universityschool)", replacement="university")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(unlike|unlikely)", replacement="unlike")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(used|uses|using)", replacement="use")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(varieties)", replacement="variety")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(verbalization|verbally)", replacement="verbal")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(viewed|viewing)", replacement="view")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(way|ways)", replacement="way")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(word|words)", replacement="word")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(working|works)", replacement="work")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(writing|writings|written)", replacement="write")
allFilesx <- tm_map(allFilesx, content_transformer(gsub), pattern = "(yearold|years)", replacement="year")
wordstoremove<-c(stopwords("english"),"can")
#allFilesx <- tm_map(allFilesx, removeWords, c("endoffile"))
allFilesx<-tm_map(allFilesx,stripWhitespace)
myWordNetwork <- function (txt,j.words) {
# Clean data
#remove capitalization
#corpus.temp          <- tm_map(corpus, tolower)
#Remove punctuations and other unnecessary things
#corpus.removed.punc  <- tm_map(corpus.temp, removePunctuation)
#Remove numbers
#corpus.removed.numb  <- tm_map(corpus.removed.punc, removeNumbers)
#Remove Whitespaces
#corpus.removed.white <- tm_map(corpus.removed.punc, stripWhitespace)
#corpus               <- Corpus(DataframeSource(data.frame(data)))
#prepare for stemming (language is english, but TM has a package for other
#languages)
#corpus.temp <- corpus.removed.white
#corpus.copy  <- corpus.temp
#corpus.temp  <- tm_map(corpus.temp, stemDocument, language = language)
#corpus.final <- tm_map(corpus.temp, stemCompletion,
#                      dictionary = corpus.copy)
#corpus.final<-corpus.temp
#Prepare to remove "stopwords" such as "A", "The", e.t.c.
# keep "declarative words"
#my.stopwords <- stopwords("english")
#my.stopwords <- my.stopwords[!(my.stopwords %in% j.words)]
#Remove stopwrods
#corpus.crop <- tm_map(corpus.removed.white,removeWords,c(my.stopwords))
# Create edge list for export
edge.list <-strsplit(as.matrix(txt), split = " ")[[1]]
#Remove unnecessary
#edge.list<-as.matrix(corpus.final[[1]])
#edge.list <- edge.list[edge.list!=""]
#edge.list<-strsplit(edge.list,split=" ")
# index of "declarative words" (the -1 is because we're removing first and
# last word to make it into a word-network
node.num <- length(edge.list[!(edge.list %in% j.words)]) - 1
#Create matrix to be exported
export.edge.list <- array("",dim=c(node.num,2))
#Set column names as per Gephi requirements
#colnames(export.edge.list) <- c("Source","Target","Label")
# Put source word except the "joining words into the matrix to be exported
export.edge.list[,1] <- edge.list[!(edge.list %in% j.words)][-length(edge.list[!(edge.list %in% j.words)])]
# put the target word except the "joining words into the matrix to be exported
export.edge.list[,2] <- edge.list[!(edge.list %in% j.words)][-1]
#Go through the joining words and put them in
# for(i in j.words) {
#  for (j in which(edge.list %in% i)) {
#  export.edge.list[j - sum(!which(edge.list %in% j.words) > j), 3] <- i
# }
#}
return(export.edge.list)
}
edgelists<-lapply(allFilesx,myWordNetwork,j.words=wordstoremove)
graphs<-list()
for (i in 1:35){
graphs[[i]]<-graph.edgelist(edgelists[[i]],directed=T)
}
allEdge<-rbind(edgelists[[1]],edgelists[[2]],edgelists[[3]],edgelists[[4]],edgelists[[5]],edgelists[[6]],edgelists[[7]],edgelists[[8]],edgelists[[9]],
edgelists[[11]],edgelists[[12]],edgelists[[13]],edgelists[[14]],edgelists[[15]],edgelists[[16]],edgelists[[17]],edgelists[[18]],edgelists[[19]],
edgelists[[21]],edgelists[[22]],edgelists[[23]],edgelists[[24]],edgelists[[25]],edgelists[[26]],edgelists[[27]],edgelists[[28]],edgelists[[29]],
edgelists[[31]],edgelists[[32]],edgelists[[33]],edgelists[[34]],edgelists[[35]])
article01<-graph.edgelist(edgelists[[1]],directed=T)
article02<-graph.edgelist(edgelists[[2]],directed=T)
article03<-graph.edgelist(edgelists[[3]],directed=T)
article04<-graph.edgelist(edgelists[[4]],directed=T)
article05<-graph.edgelist(edgelists[[5]],directed=T)
article06<-graph.edgelist(edgelists[[6]],directed=T)
article07<-graph.edgelist(edgelists[[7]],directed=T)
article08<-graph.edgelist(edgelists[[8]],directed=T)
article09<-graph.edgelist(edgelists[[9]],directed=T)
article10<-graph.edgelist(edgelists[[10]],directed=T)
article11<-graph.edgelist(edgelists[[11]],directed=T)
article12<-graph.edgelist(edgelists[[12]],directed=T)
article13<-graph.edgelist(edgelists[[13]],directed=T)
article14<-graph.edgelist(edgelists[[14]],directed=T)
article15<-graph.edgelist(edgelists[[15]],directed=T)
article16<-graph.edgelist(edgelists[[16]],directed=T)
article17<-graph.edgelist(edgelists[[17]],directed=T)
article18<-graph.edgelist(edgelists[[18]],directed=T)
article19<-graph.edgelist(edgelists[[19]],directed=T)
article20<-graph.edgelist(edgelists[[20]],directed=T)
article21<-graph.edgelist(edgelists[[21]],directed=T)
article22<-graph.edgelist(edgelists[[22]],directed=T)
article23<-graph.edgelist(edgelists[[23]],directed=T)
article24<-graph.edgelist(edgelists[[24]],directed=T)
article25<-graph.edgelist(edgelists[[25]],directed=T)
article26<-graph.edgelist(edgelists[[26]],directed=T)
article27<-graph.edgelist(edgelists[[27]],directed=T)
article28<-graph.edgelist(edgelists[[28]],directed=T)
article29<-graph.edgelist(edgelists[[29]],directed=T)
article30<-graph.edgelist(edgelists[[30]],directed=T)
article31<-graph.edgelist(edgelists[[31]],directed=T)
article32<-graph.edgelist(edgelists[[32]],directed=T)
article33<-graph.edgelist(edgelists[[33]],directed=T)
article34<-graph.edgelist(edgelists[[34]],directed=T)
article35<-graph.edgelist(edgelists[[35]],directed=T)
allNet<-graph.edgelist(allEdge,directed=T)
write.graph(allNet,"allNet.graphml",format="graphml")
write.graph(article01,"article01.graphml",format="graphml")
write.graph(article02,"article02.graphml",format="graphml")
write.graph(article03,"article03.graphml",format="graphml")
write.graph(article04,"article04.graphml",format="graphml")
write.graph(article05,"article05.graphml",format="graphml")
write.graph(article06,"article06.graphml",format="graphml")
write.graph(article07,"article07.graphml",format="graphml")
write.graph(article08,"article08.graphml",format="graphml")
write.graph(article09,"article09.graphml",format="graphml")
write.graph(article10,"article10.graphml",format="graphml")
write.graph(article11,"article11.graphml",format="graphml")
write.graph(article12,"article12.graphml",format="graphml")
write.graph(article13,"article13.graphml",format="graphml")
write.graph(article14,"article14.graphml",format="graphml")
write.graph(article15,"article15.graphml",format="graphml")
write.graph(article16,"article16.graphml",format="graphml")
write.graph(article17,"article17.graphml",format="graphml")
write.graph(article18,"article18.graphml",format="graphml")
write.graph(article20,"article20.graphml",format="graphml")
write.graph(article21,"article21.graphml",format="graphml")
write.graph(article22,"article22.graphml",format="graphml")
write.graph(article23,"article23.graphml",format="graphml")
write.graph(article24,"article24.graphml",format="graphml")
write.graph(article25,"article25.graphml",format="graphml")
write.graph(article26,"article26.graphml",format="graphml")
write.graph(article27,"article27.graphml",format="graphml")
write.graph(article28,"article28.graphml",format="graphml")
write.graph(article29,"article29.graphml",format="graphml")
write.graph(article30,"article30.graphml",format="graphml")
write.graph(article31,"article31.graphml",format="graphml")
write.graph(article32,"article32.graphml",format="graphml")
write.graph(article33,"article33.graphml",format="graphml")
write.graph(article34,"article34.graphml",format="graphml")
write.graph(article35,"article35.graphml",format="graphml")
write.csv(V(allNet)$name,"listNodes.csv")
allNet
plot(allNet)
allFilesx <- tm_map(allFilesx, removeWords,wordstoremove)
##-ngrams###
str<- concatenate(lapply(allFilesx ,"[", 1))
ngall1<- ngram(str, n=1)
ngall2<- ngram(str, n=2)
ngall3<- ngram(str, n=3)
ngall4<- ngram(str, n=4)
ngall5<- ngram(str, n=5)
ngall6<- ngram(str, n=6)
ngall7<- ngram(str, n=7)
ngall8<- ngram(str, n=8)
str1<-concatenate(allFilesx[[1]])
pmat<-function(data,probs){
pmat<-matrix(0,ncol=length(data[1,]),nrow=length(data[,1]))
for(j in 1:length(data[,1])){
pmat[j,]<-data[j,]*probs
}
infmat<--log2(pmat)
infmat[which(!is.finite(infmat))] <- NA
return(infmat)
}
simRes<-function(i,j,infmat,d){
y<-infmat[i,]
overlap<-sum(y[which(d[i,]==d[j,])],na.rm=T)
sinfi<-sum(infmat[i,],na.rm=T)
sinfj<-sum(infmat[j,],na.rm=T)
sim<-2*overlap/(sinfi+sinfj)
return(sim)
}
simResk<-function(k,inf,d){
simVec<-vector()
for(i in 1:length(d[,1])){
simVec[i]<-simRes(k,i,inf,d)
}
return(simVec)
}
simMatrix<-function(d,probs){
inf<-pmat(d,probs)
similarityMatrix<-matrix(data=0,ncol=length(d[,1]),nrow=length(d[,1]))
for(i in 1:length(d[,1])){
similarityMatrix[,i]<-simResk(i,inf,d)
}
return(similarityMatrix)
}
str1<-vector()
for(i in 1:length(allFilesx)){
str1[i]<-concatenate(allFilesx[[i]])
}
ng1<-list()
for(i in 1:length(allFilesx)){
ng1[i]<-ngram(str1[i],n=1)
}
g1simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall1)))
dim(g1simMat)
for(i in 1:length(allFilesx)){
str1[i]<-concatenate(allFilesx[[i]])
}
unique1grams<-sort(get.ngrams(ngall1))
colnames(g1simMat)<-unique1grams
for (i in 1:length(allFilesx)){
g1simMat[i,]<-as.numeric(unique1grams%in%get.ngrams(ng1[i][[1]]))
}
grams<-get.phrasetable(ngall1)[,1]
frequencies<-get.phrasetable(ngall1)[,2] #not needed
probabilities<-get.phrasetable(ngall1)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g1simMat,probs)
net1gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
net1gram
###2-gram overlap
ng2<-list()
for(i in 1:length(allFilesx)){
ng2[i]<-ngram(str1[i],n=2)
}
g2simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall2)))
unique2grams<-sort(get.ngrams(ngall2))
colnames(g2simMat)<-unique2grams
for (i in 1:length(allFilesx)){
g2simMat[i,]<-as.numeric(unique2grams%in%get.ngrams(ng2[i][[1]]))
}
grams<-get.phrasetable(ngall2)[,1]
frequencies<-get.phrasetable(ngall2)[,2] #not needed
probabilities<-get.phrasetable(ngall2)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g2simMat,probs)
net2gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
net2gram
E(net1gram)$weight
hist(E(net1gram)$weight)
hist(E(net2gram)$weight)
mean(E(net2gram)$weight)
sd(E(net2gram)$weight)
###3-gram overlap
ng3<-list()
for(i in 1:length(allFilesx)){
ng3[i]<-ngram(str1[i],n=3)
}
g3simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall3)))
unique3grams<-sort(get.ngrams(ngall3))
colnames(g3simMat)<-unique3grams
for (i in 1:length(allFilesx)){
g3simMat[i,]<-as.numeric(unique3grams%in%get.ngrams(ng3[i][[1]]))
}
grams<-get.phrasetable(ngall3)[,1]
frequencies<-get.phrasetable(ngall3)[,2] #not needed
probabilities<-get.phrasetable(ngall3)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g3simMat,probs)
net3gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
###4-gram overlap
ng4<-list()
for(i in 1:length(allFilesx)){
ng4[i]<-ngram(str1[i],n=4)
}
g4simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall4)))
unique4grams<-sort(get.ngrams(ngall4))
colnames(g4simMat)<-unique4grams
for (i in 1:length(allFilesx)){
g4simMat[i,]<-as.numeric(unique4grams%in%get.ngrams(ng4[i][[1]]))
}
grams<-get.phrasetable(ngall4)[,1]
frequencies<-get.phrasetable(ngall4)[,2] #not needed
probabilities<-get.phrasetable(ngall4)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g4simMat,probs)
net4gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
###5-gram overlap
ng5<-list()
for(i in 1:length(allFilesx)){
ng5[i]<-ngram(str1[i],n=5)
}
g5simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall5)))
unique5grams<-sort(get.ngrams(ngall5))
colnames(g5simMat)<-unique5grams
for (i in 1:length(allFilesx)){
g5simMat[i,]<-as.numeric(unique5grams%in%get.ngrams(ng5[i][[1]]))
}
grams<-get.phrasetable(ngall5)[,1]
frequencies<-get.phrasetable(ngall5)[,2] #not needed
probabilities<-get.phrasetable(ngall5)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g5simMat,probs)
net5gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
###6-gram overlap
ng6<-list()
for(i in 1:length(allFilesx)){
ng6[i]<-ngram(str1[i],n=6)
}
g6simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall6)))
unique6grams<-sort(get.ngrams(ngall6))
colnames(g6simMat)<-unique6grams
for (i in 1:length(allFilesx)){
g6simMat[i,]<-as.numeric(unique6grams%in%get.ngrams(ng6[i][[1]]))
}
grams<-get.phrasetable(ngall6)[,1]
frequencies<-get.phrasetable(ngall6)[,2] #not needed
probabilities<-get.phrasetable(ngall6)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g6simMat,probs)
net6gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
###7-gram overlap
ng7<-list()
for(i in 1:length(allFilesx)){
ng7[i]<-ngram(str1[i],n=7)
}
g7simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall7)))
unique7grams<-sort(get.ngrams(ngall7))
colnames(g7simMat)<-unique7grams
for (i in 1:length(allFilesx)){
g7simMat[i,]<-as.numeric(unique7grams%in%get.ngrams(ng7[i][[1]]))
}
grams<-get.phrasetable(ngall7)[,1]
frequencies<-get.phrasetable(ngall7)[,2] #not needed
probabilities<-get.phrasetable(ngall7)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g7simMat,probs)
net7gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
###8-gram overlap
ng8<-list()
for(i in 1:length(allFilesx)){
ng8[i]<-ngram(str1[i],n=8)
}
g8simMat<-matrix(data=0,nrow = length(allFilesx),ncol = length(get.ngrams(ngall8)))
unique8grams<-sort(get.ngrams(ngall8))
colnames(g8simMat)<-unique8grams
for (i in 1:length(allFilesx)){
g8simMat[i,]<-as.numeric(unique8grams%in%get.ngrams(ng8[i][[1]]))
}
grams<-get.phrasetable(ngall8)[,1]
frequencies<-get.phrasetable(ngall8)[,2] #not needed
probabilities<-get.phrasetable(ngall8)[,3]
probs<-probabilities[order(grams)] #corpus wide probabilities of words
testSim<-simMatrix(g8simMat,probs)
net8gram<-graph.adjacency(testSim,diag=F,weighted=T,mode = "upper")
net3gram
plot(net3gram)
plot(net2gram)
plot(net1gram)
net1gramBB<-backboneNetwork(net1gram,0.05,2)
net1grammBB
net1gram
V(net1gram)
V(net1gram)$id
V(net1gram)$id<-c(1:35)
net1gramBB<-backboneNetwork(net1gram,0.05,2)
net1gramBB
plot(net1gramBB)
net1gramBB<-backboneNetwork(net1gram,0.01,2)
net1gramBB
net1gramBB<-backboneNetwork(net1gram,0.02,2)
net1gramBB<-backboneNetwork(net1gram,0.02,2)
net1gramBB
net1gramBB<-backboneNetwork(net1gram,0.04,2)
net1gramBB
net1gramBB<-backboneNetwork(net1gram,0.05,2)
net1gramBB
V(net2gram)$id<-c(1:35)
net2gramBB<-backboneNetwork(net2gram,0.05,2)
net2gramBB
net2gramBB<-backboneNetwork(net2gram,0.01,2)
net2gramBB
net2gramBB<-backboneNetwork(net2gram,0.04,2)
net2gramBB
is.connected(net2gramBB)
net2gramBB<-backboneNetwork(net2gram,0.05,2)
is.connected(net2gramBB)
plot(net2gramBB)
is.connected(net1gramBB)
net1gramBB<-backboneNetwork(net1gram,0.01,2)
net1gramBB<-backboneNetwork(net1gram,0.0001,2)
net1gramBB
net2gramBB<-backboneNetwork(net2gram,0.0001,2)
net2gramBB
plot(net2gramBB)
write.graph(net1gram,"net1gram.graphml",format="graphml")
write.graph(net2gram,"net2gram.graphml",format="graphml")
write.graph(net1gramBB,"net1gramBB.graphml",format="graphml")
write.graph(net2gramBB,"net2gramBB.graphml",format="graphml")
write.graph(net3gram,"net3gram.graphml",format="graphml")
write.graph(net4gram,"net4gram.graphml",format="graphml")
write.graph(net5gram,"net5gram.graphml",format="graphml")
write.graph(net6gram,"net6gram.graphml",format="graphml")
write.graph(net7gram,"net7gram.graphml",format="graphml")
write.graph(net8gram,"net8gram.graphml",format="graphml")
net1gramBB
net3gram
is.connected(net2gram)
V(net1gram)$id<-c(1:35)
net1gramBB<-backboneNetwork(net1gram,0.04,2)
is.connected(n2gram)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.03,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.02,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.025,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.027,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.029,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.029999,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.0299,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.029,2)
is.connected(net1gramBB
)
net1gramBB<-backboneNetwork(net1gram,0.0295,2)
is.connected(net1gramBB
)
net1gramBB
write.graph(net1gram,"net1gram.graphml",format="graphml")
write.graph(net2gram,"net2gram.graphml",format="graphml")
write.graph(net1gramBB,"net1gramBB.graphml",format="graphml")
write.graph(net2gramBB,"net2gramBB.graphml",format="graphml")
write.graph(net3gram,"net3gram.graphml",format="graphml")
write.graph(net4gram,"net4gram.graphml",format="graphml")
write.graph(net5gram,"net5gram.graphml",format="graphml")
write.graph(net6gram,"net6gram.graphml",format="graphml")
write.graph(net7gram,"net7gram.graphml",format="graphml")
write.graph(net8gram,"net8gram.graphml",format="graphml")
net4gram
net5gram
links<-c(ecount(net1gram),ecount(net2gram),ecount(net3gram),ecount(net4gram),ecount(net5gram),ecount(net6gram),ecount(net7gram),ecount(net8gram))
x<-c(1:8)
plot(x,links)
plot(x,links,log="xy")
plot(x,links,log="y")
plot(x,links,log="xy")
plot(x,1/links)
plot(x,links)
net3gramBB<-backboneNetwork(net3gram,0.0001,2)
V(net3gram)$id<-c(1:35)
net3gramBB<-backboneNetwork(net3gram,0.0001,2)
net3gramBB
plot(net3gramBB)
write.graph(net3gram,"net3gramBB.graphml",format="graphml")
write.graph(net3gramBB,"net3gramBB.graphml",format="graphml")
